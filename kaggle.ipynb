{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce3ee460",
   "metadata": {},
   "source": [
    "# Artistic QR Code Generation on Kaggle\n",
    "\n",
    "This notebook generates artistic images with embedded scannable QR codes using Stable Diffusion and ControlNet.\n",
    "\n",
    "## Features\n",
    "- Generate artistic images with embedded QR codes\n",
    "- Support for both ControlNet and post-processing embedding methods\n",
    "- Automatic QR code validation\n",
    "- GPU acceleration support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783f5602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q diffusers>=0.21.0 transformers>=4.30.0 accelerate>=0.20.0\n",
    "!pip install -q qrcode[pil]>=7.4.2 Pillow>=10.0.0\n",
    "!pip install -q pyzbar opencv-python\n",
    "!pip install -q scipy  # Optional, for edge enhancement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7ab3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import qrcode\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from diffusers import StableDiffusionPipeline, StableDiffusionControlNetPipeline, ControlNetModel\n",
    "from typing import Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check GPU availability\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098b59be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle-specific paths\n",
    "KAGGLE_WORKING = \"/kaggle/working\"\n",
    "KAGGLE_INPUT = \"/kaggle/input\"\n",
    "OUTPUT_DIR = os.path.join(KAGGLE_WORKING, \"outputs\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Set up Hugging Face cache (use working directory)\n",
    "HF_CACHE = os.path.join(KAGGLE_WORKING, \"hf_cache\")\n",
    "os.makedirs(HF_CACHE, exist_ok=True)\n",
    "os.environ[\"HF_HOME\"] = HF_CACHE\n",
    "os.environ[\"HF_HUB_CACHE\"] = os.path.join(HF_CACHE, \"hub\")\n",
    "\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"HF Cache: {HF_CACHE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6b1619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artistic QR Pipeline Class (Kaggle-adapted)\n",
    "class ArtisticQRPipeline:\n",
    "    \"\"\"Complete pipeline for generating artistic images with embedded QR codes.\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 model_id: str = \"runwayml/stable-diffusion-v1-5\",\n",
    "                 cache_dir: str = None,\n",
    "                 device: Optional[str] = None):\n",
    "        self.model_id = model_id\n",
    "        self.cache_dir = cache_dir or HF_CACHE\n",
    "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.pipe = None\n",
    "        self.controlnet_pipe = None\n",
    "        self.controlnet_model = None\n",
    "        \n",
    "    def create_qr_code(self, data: str, size: int = 512, border: int = 4, \n",
    "                       error_correction: str = \"H\") -> Image.Image:\n",
    "        \"\"\"Create a QR code with specified parameters.\"\"\"\n",
    "        error_levels = {\n",
    "            'L': qrcode.constants.ERROR_CORRECT_L,\n",
    "            'M': qrcode.constants.ERROR_CORRECT_M,\n",
    "            'Q': qrcode.constants.ERROR_CORRECT_Q,\n",
    "            'H': qrcode.constants.ERROR_CORRECT_H\n",
    "        }\n",
    "        \n",
    "        qr = qrcode.QRCode(\n",
    "            version=1,\n",
    "            error_correction=error_levels.get(error_correction.upper(), qrcode.constants.ERROR_CORRECT_H),\n",
    "            box_size=10,\n",
    "            border=border,\n",
    "        )\n",
    "        qr.add_data(data)\n",
    "        qr.make(fit=True)\n",
    "        \n",
    "        qr_img = qr.make_image(fill_color=\"black\", back_color=\"white\")\n",
    "        qr_img = qr_img.resize((size, size), Image.Resampling.LANCZOS)\n",
    "        return qr_img\n",
    "    \n",
    "    def load_model(self):\n",
    "        \"\"\"Load the Stable Diffusion model.\"\"\"\n",
    "        if self.pipe is not None:\n",
    "            return self.pipe\n",
    "        \n",
    "        print(f\"Loading Stable Diffusion model: {self.model_id}\")\n",
    "        dtype = torch.float16 if self.device == \"cuda\" else torch.float32\n",
    "        \n",
    "        self.pipe = StableDiffusionPipeline.from_pretrained(\n",
    "            self.model_id,\n",
    "            torch_dtype=dtype,\n",
    "            cache_dir=self.cache_dir\n",
    "        ).to(self.device)\n",
    "        \n",
    "        if self.device == \"cuda\":\n",
    "            try:\n",
    "                self.pipe.enable_xformers_memory_efficient_attention()\n",
    "            except:\n",
    "                print(\"xformers not available, continuing without it\")\n",
    "        \n",
    "        print(\"Model loaded successfully!\")\n",
    "        return self.pipe\n",
    "    \n",
    "    def load_controlnet_model(self):\n",
    "        \"\"\"Load ControlNet model for QR code generation.\"\"\"\n",
    "        if self.controlnet_pipe is not None:\n",
    "            return self.controlnet_pipe\n",
    "        \n",
    "        print(\"Loading ControlNet QR code model...\")\n",
    "        dtype = torch.float16 if self.device == \"cuda\" else torch.float32\n",
    "        \n",
    "        # Try different ControlNet models\n",
    "        controlnet_models = [\n",
    "            \"monster-labs/control_v1p_sd15_qrcode_monster\",\n",
    "            \"DionTimmer/controlnet_qrcode-control_v11p_sd15\",\n",
    "        ]\n",
    "        \n",
    "        controlnet = None\n",
    "        for model_id in controlnet_models:\n",
    "            try:\n",
    "                print(f\"Trying ControlNet model: {model_id}\")\n",
    "                controlnet = ControlNetModel.from_pretrained(\n",
    "                    model_id,\n",
    "                    torch_dtype=dtype,\n",
    "                    cache_dir=self.cache_dir\n",
    "                )\n",
    "                print(f\"Successfully loaded: {model_id}\")\n",
    "                self.controlnet_model = model_id\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to load {model_id}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if controlnet is None:\n",
    "            raise RuntimeError(\"Could not load any ControlNet QR code model\")\n",
    "        \n",
    "        self.controlnet_pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
    "            self.model_id,\n",
    "            controlnet=controlnet,\n",
    "            torch_dtype=dtype,\n",
    "            cache_dir=self.cache_dir,\n",
    "            safety_checker=None,\n",
    "            requires_safety_checker=False\n",
    "        ).to(self.device)\n",
    "        \n",
    "        if self.device == \"cuda\":\n",
    "            try:\n",
    "                self.controlnet_pipe.enable_xformers_memory_efficient_attention()\n",
    "            except:\n",
    "                print(\"xformers not available, continuing without it\")\n",
    "        \n",
    "        print(\"ControlNet model loaded successfully!\")\n",
    "        return self.controlnet_pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c431281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue with embedding methods\n",
    "def embed_qr_artistically(base_image, qr_image, subtlety=0.88, contrast_boost=0.08):\n",
    "    \"\"\"Embed QR code into image artistically.\"\"\"\n",
    "    if base_image.mode != 'RGB':\n",
    "        base_image = base_image.convert('RGB')\n",
    "    if qr_image.mode != 'RGB':\n",
    "        qr_image = qr_image.convert('RGB')\n",
    "    \n",
    "    target_size = max(base_image.size)\n",
    "    base_image = base_image.resize((target_size, target_size), Image.Resampling.LANCZOS)\n",
    "    qr_image = qr_image.resize((target_size, target_size), Image.Resampling.LANCZOS)\n",
    "    \n",
    "    base_array = np.array(base_image, dtype=float)\n",
    "    qr_array = np.array(qr_image, dtype=float)\n",
    "    \n",
    "    # Convert QR code to binary mask\n",
    "    qr_gray = np.dot(qr_array[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "    threshold = 127\n",
    "    qr_binary = (qr_gray < threshold).astype(float)\n",
    "    qr_mask_3d = np.expand_dims(qr_binary, axis=2)\n",
    "    \n",
    "    # Calculate contrast\n",
    "    min_contrast = 0.20\n",
    "    if subtlety <= 0.85:\n",
    "        effective_contrast = 0.25\n",
    "    elif subtlety <= 0.88:\n",
    "        effective_contrast = 0.25 - (subtlety - 0.85) * (0.25 - 0.22) / (0.88 - 0.85)\n",
    "    elif subtlety <= 0.90:\n",
    "        effective_contrast = 0.22 - (subtlety - 0.88) * (0.22 - 0.20) / (0.90 - 0.88)\n",
    "    else:\n",
    "        effective_contrast = min_contrast\n",
    "    effective_contrast = max(effective_contrast, min_contrast)\n",
    "    \n",
    "    dark_factor = 1.0 - effective_contrast\n",
    "    light_factor = 1.0 + effective_contrast\n",
    "    \n",
    "    result_array = base_array.copy()\n",
    "    \n",
    "    # Apply embedding\n",
    "    dark_mask = qr_mask_3d\n",
    "    result_array = result_array * (1 - dark_mask * (1 - dark_factor))\n",
    "    \n",
    "    light_mask = 1 - qr_mask_3d\n",
    "    result_array = result_array * (1 + light_mask * (light_factor - 1))\n",
    "    \n",
    "    # Contrast boost\n",
    "    if contrast_boost > 0:\n",
    "        qr_contrast = (qr_mask_3d - 0.5) * 2\n",
    "        contrast_multiplier = 100 if subtlety >= 0.88 else 80\n",
    "        contrast_strength = contrast_boost * contrast_multiplier\n",
    "        result_array = result_array + (qr_contrast * contrast_strength)\n",
    "    \n",
    "    # Pattern enhancement\n",
    "    qr_pattern_diff = (qr_mask_3d - 0.5) * 2\n",
    "    pattern_enhancement = 15.0\n",
    "    result_array = result_array + (qr_pattern_diff * pattern_enhancement)\n",
    "    \n",
    "    result_array = np.clip(result_array, 0, 255).astype(np.uint8)\n",
    "    return Image.fromarray(result_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2b9b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add methods to pipeline class\n",
    "def generate_with_controlnet(self, prompt, qr_data, output_path, image_size=512,\n",
    "                             num_inference_steps=30, guidance_scale=7.5,\n",
    "                             controlnet_conditioning_scale=1.5, seed=None,\n",
    "                             qr_enhancement_strength=0.20):\n",
    "    \"\"\"Generate artistic QR code using ControlNet.\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ControlNet Artistic QR Code Generation\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create QR code\n",
    "    print(\"\\n[Step 1/2] Creating QR code...\")\n",
    "    qr_image = self.create_qr_code(qr_data, size=image_size)\n",
    "    qr_image = qr_image.convert(\"RGB\")\n",
    "    \n",
    "    # Save original QR\n",
    "    qr_ref_path = output_path.replace('.png', '_original_qr.png')\n",
    "    qr_image.save(qr_ref_path)\n",
    "    print(f\"Original QR code saved: {qr_ref_path}\")\n",
    "    \n",
    "    # Load ControlNet\n",
    "    print(\"\\n[Step 2/2] Generating image with ControlNet...\")\n",
    "    pipe = self.load_controlnet_model()\n",
    "    \n",
    "    generator = None\n",
    "    if seed is not None:\n",
    "        generator = torch.Generator(device=self.device).manual_seed(seed)\n",
    "    \n",
    "    image = pipe(\n",
    "        prompt=prompt,\n",
    "        negative_prompt=\"blurry, distorted, unreadable qr, low quality\",\n",
    "        image=qr_image,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "        guidance_scale=guidance_scale,\n",
    "        controlnet_conditioning_scale=controlnet_conditioning_scale,\n",
    "        generator=generator\n",
    "    ).images[0]\n",
    "    \n",
    "    # Enhance QR scannability\n",
    "    print(\"\\n[Step 3/3] Enhancing QR code scannability...\")\n",
    "    image = enhance_qr_scannability(image, qr_image, qr_enhancement_strength)\n",
    "    \n",
    "    image.save(output_path)\n",
    "    print(f\"\\n✓ ControlNet artistic QR code saved to: {output_path}\")\n",
    "    return image\n",
    "\n",
    "def enhance_qr_scannability(generated_image, qr_reference, enhancement_strength=0.20):\n",
    "    \"\"\"Enhance QR code scannability in ControlNet-generated images.\"\"\"\n",
    "    if generated_image.mode != 'RGB':\n",
    "        generated_image = generated_image.convert('RGB')\n",
    "    if qr_reference.mode != 'RGB':\n",
    "        qr_reference = qr_reference.convert('RGB')\n",
    "    \n",
    "    target_size = generated_image.size[0]\n",
    "    qr_reference = qr_reference.resize((target_size, target_size), Image.Resampling.LANCZOS)\n",
    "    \n",
    "    gen_array = np.array(generated_image, dtype=float)\n",
    "    qr_array = np.array(qr_reference, dtype=float)\n",
    "    \n",
    "    qr_gray = np.dot(qr_array[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "    threshold = 127\n",
    "    qr_binary = (qr_gray < threshold).astype(float)\n",
    "    qr_mask_3d = np.expand_dims(qr_binary, axis=2)\n",
    "    \n",
    "    result_array = gen_array.copy()\n",
    "    \n",
    "    dark_mask = qr_mask_3d\n",
    "    darken_factor = 1.0 - (enhancement_strength * 0.5)\n",
    "    result_array = result_array * (1 - dark_mask * (1 - darken_factor))\n",
    "    \n",
    "    light_mask = 1 - qr_mask_3d\n",
    "    lighten_factor = 1.0 + (enhancement_strength * 0.5)\n",
    "    result_array = result_array * (1 + light_mask * (lighten_factor - 1))\n",
    "    \n",
    "    contrast_boost = enhancement_strength * 30\n",
    "    qr_contrast = (qr_mask_3d - 0.5) * 2\n",
    "    result_array = result_array + (qr_contrast * contrast_boost)\n",
    "    \n",
    "    result_array = np.clip(result_array, 0, 255).astype(np.uint8)\n",
    "    return Image.fromarray(result_array)\n",
    "\n",
    "# Attach methods to class\n",
    "ArtisticQRPipeline.generate_with_controlnet = generate_with_controlnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941271f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete pipeline method\n",
    "def process(self, prompt, qr_data, output_path, image_size=512, subtlety=0.88,\n",
    "           num_inference_steps=50, guidance_scale=7.5, seed=None,\n",
    "           use_controlnet=False, controlnet_conditioning_scale=1.5,\n",
    "           qr_enhancement_strength=0.20):\n",
    "    \"\"\"Complete pipeline: Generate image and embed QR code.\"\"\"\n",
    "    \n",
    "    if use_controlnet:\n",
    "        return self.generate_with_controlnet(\n",
    "            prompt=prompt, qr_data=qr_data, output_path=output_path,\n",
    "            image_size=image_size, num_inference_steps=num_inference_steps,\n",
    "            guidance_scale=guidance_scale, controlnet_conditioning_scale=controlnet_conditioning_scale,\n",
    "            seed=seed, qr_enhancement_strength=qr_enhancement_strength\n",
    "        )\n",
    "    \n",
    "    # Post-processing embedding method\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Artistic QR Code Image Generation Pipeline\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Step 1: Create QR code\n",
    "    print(\"\\n[Step 1/3] Creating QR code...\")\n",
    "    qr_image = self.create_qr_code(qr_data, size=image_size)\n",
    "    \n",
    "    qr_ref_path = output_path.replace('.png', '_original_qr.png')\n",
    "    qr_image.save(qr_ref_path)\n",
    "    print(f\"Original QR code saved: {qr_ref_path}\")\n",
    "    \n",
    "    # Step 2: Generate artistic image\n",
    "    print(\"\\n[Step 2/3] Generating artistic image...\")\n",
    "    if self.pipe is None:\n",
    "        self.load_model()\n",
    "    \n",
    "    generator = None\n",
    "    if seed is not None:\n",
    "        generator = torch.Generator(device=self.device).manual_seed(seed)\n",
    "    \n",
    "    generated_image = self.pipe(\n",
    "        prompt,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "        guidance_scale=guidance_scale,\n",
    "        generator=generator\n",
    "    ).images[0]\n",
    "    \n",
    "    generated_image = generated_image.resize((image_size, image_size), Image.Resampling.LANCZOS)\n",
    "    \n",
    "    # Step 3: Embed QR code\n",
    "    print(\"\\n[Step 3/3] Embedding QR code artistically...\")\n",
    "    contrast_boost_value = 0.08 if subtlety >= 0.90 else 0.06\n",
    "    final_image = embed_qr_artistically(\n",
    "        generated_image, qr_image, subtlety=subtlety, contrast_boost=contrast_boost_value\n",
    "    )\n",
    "    \n",
    "    final_image.save(output_path)\n",
    "    print(f\"\\n✓ Artistic QR code image saved to: {output_path}\")\n",
    "    return final_image\n",
    "\n",
    "ArtisticQRPipeline.process = process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67371ea",
   "metadata": {},
   "source": [
    "## Generate Artistic QR Code\n",
    "\n",
    "Now let's generate an artistic QR code image. You can customize the parameters below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e3f9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "PROMPT = \"a king looking up at the sky, white fluffy clouds in blue sky, beautiful sunset colors, artistic illustration, detailed fur texture, expressive eyes, QR code pattern subtly integrated into clouds and sky background, high quality, vibrant colors\"\n",
    "QR_DATA = \"https://example.com\"\n",
    "IMAGE_SIZE = 512\n",
    "USE_CONTROLNET = True  # Set to False for post-processing embedding\n",
    "SEED = 42\n",
    "\n",
    "# ControlNet parameters (only used if USE_CONTROLNET=True)\n",
    "CONTROLNET_CONDITIONING_SCALE = 1.5\n",
    "QR_ENHANCEMENT_STRENGTH = 0.20\n",
    "\n",
    "# Post-processing parameters (only used if USE_CONTROLNET=False)\n",
    "SUBTLETY = 0.88\n",
    "\n",
    "# Generation parameters\n",
    "NUM_INFERENCE_STEPS = 30 if USE_CONTROLNET else 50\n",
    "GUIDANCE_SCALE = 7.5\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Prompt: {PROMPT[:50]}...\")\n",
    "print(f\"  QR Data: {QR_DATA}\")\n",
    "print(f\"  Method: {'ControlNet' if USE_CONTROLNET else 'Post-processing Embedding'}\")\n",
    "print(f\"  Image Size: {IMAGE_SIZE}\")\n",
    "print(f\"  Seed: {SEED}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e5efff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pipeline\n",
    "pipeline = ArtisticQRPipeline(\n",
    "    model_id=\"runwayml/stable-diffusion-v1-5\",\n",
    "    cache_dir=HF_CACHE,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Generate QR code\n",
    "output_filename = \"artistic_qr_output.png\"\n",
    "output_path = os.path.join(OUTPUT_DIR, output_filename)\n",
    "\n",
    "print(\"\\nStarting generation...\")\n",
    "final_image = pipeline.process(\n",
    "    prompt=PROMPT,\n",
    "    qr_data=QR_DATA,\n",
    "    output_path=output_path,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    subtlety=SUBTLETY,\n",
    "    num_inference_steps=NUM_INFERENCE_STEPS,\n",
    "    guidance_scale=GUIDANCE_SCALE,\n",
    "    seed=SEED,\n",
    "    use_controlnet=USE_CONTROLNET,\n",
    "    controlnet_conditioning_scale=CONTROLNET_CONDITIONING_SCALE,\n",
    "    qr_enhancement_strength=QR_ENHANCEMENT_STRENGTH\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ Generation complete!\")\n",
    "print(f\"Output saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2531d813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the generated image\n",
    "from IPython.display import Image as IPImage, display\n",
    "\n",
    "display(IPImage(output_path, width=512))\n",
    "print(f\"\\nGenerated QR Code Image\")\n",
    "print(f\"QR Data: {QR_DATA}\")\n",
    "\n",
    "# Also display original QR for comparison\n",
    "qr_ref_path = output_path.replace('.png', '_original_qr.png')\n",
    "if os.path.exists(qr_ref_path):\n",
    "    print(\"\\nOriginal QR Code (for comparison):\")\n",
    "    display(IPImage(qr_ref_path, width=256))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08ae7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Validate QR code scannability\n",
    "try:\n",
    "    from pyzbar.pyzbar import decode as pyzbar_decode\n",
    "    import cv2\n",
    "    \n",
    "    def validate_qr(image_path, expected_data=None):\n",
    "        \"\"\"Validate QR code scannability.\"\"\"\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            return {\"scannable\": False, \"error\": \"Could not read image\"}\n",
    "        \n",
    "        # Try OpenCV QRCodeDetector\n",
    "        detector = cv2.QRCodeDetector()\n",
    "        retval, decoded_info, points, straight_qrcode = detector.detectAndDecodeMulti(img)\n",
    "        \n",
    "        if retval and decoded_info:\n",
    "            for info in decoded_info:\n",
    "                if info:\n",
    "                    matches = (info == expected_data) if expected_data else True\n",
    "                    return {\n",
    "                        \"scannable\": True,\n",
    "                        \"data_decoded\": info,\n",
    "                        \"matches_expected\": matches\n",
    "                    }\n",
    "        \n",
    "        # Try PyZBar\n",
    "        pil_img = Image.open(image_path)\n",
    "        img_array = np.array(pil_img.convert('RGB'))\n",
    "        decoded_objects = pyzbar_decode(img_array)\n",
    "        \n",
    "        if decoded_objects:\n",
    "            for obj in decoded_objects:\n",
    "                if obj.type == 'QRCODE':\n",
    "                    decoded = obj.data.decode('utf-8')\n",
    "                    matches = (decoded == expected_data) if expected_data else True\n",
    "                    return {\n",
    "                        \"scannable\": True,\n",
    "                        \"data_decoded\": decoded,\n",
    "                        \"matches_expected\": matches\n",
    "                    }\n",
    "        \n",
    "        return {\"scannable\": False, \"error\": \"Could not decode QR code\"}\n",
    "    \n",
    "    # Validate\n",
    "    print(\"Validating QR code scannability...\")\n",
    "    result = validate_qr(output_path, QR_DATA)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"QR Code Validation Results\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Scannable: {'✅ YES' if result['scannable'] else '❌ NO'}\")\n",
    "    if result.get('data_decoded'):\n",
    "        print(f\"Decoded Data: {result['data_decoded']}\")\n",
    "        if 'matches_expected' in result:\n",
    "            print(f\"Matches Expected: {'✅ YES' if result['matches_expected'] else '❌ NO'}\")\n",
    "    if result.get('error'):\n",
    "        print(f\"Error: {result['error']}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"⚠️  QR validation libraries not available. Install pyzbar and opencv-python for validation.\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️  Validation error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c34ed3",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- **Output files** are saved to `/kaggle/working/outputs/`\n",
    "- **Models** are cached in `/kaggle/working/hf_cache/`\n",
    "- **GPU** is automatically detected and used if available\n",
    "- **ControlNet** method generally produces more scannable QR codes\n",
    "- Adjust `subtlety` (0.85-0.95) for post-processing method - lower = more visible QR\n",
    "- Adjust `qr_enhancement_strength` (0.15-0.25) for ControlNet method - higher = more visible QR\n",
    "\n",
    "## Tips for Better Scannability\n",
    "\n",
    "1. **Use ControlNet** (`use_controlnet=True`) for better results\n",
    "2. **Lower subtlety** (0.85-0.88) for post-processing method\n",
    "3. **Higher enhancement strength** (0.20-0.25) for ControlNet method\n",
    "4. **Test with phone camera** - sometimes works even if validation fails\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
